{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Stage 2\n",
    "The messages in what I called the \"mq_sgcn_items\" message queue contain records from ScienceBase that should have a new file to process. Those files contain names of species that the states/territories consider to be of greatest conservation need. There is some messiness in the data as there are cases where there may not be known scientific names or other information has been added to the spreadsheets that can get in the way of nice, clean processing to align the names with taxonomic authorities and put together other details. The initial processing step that slurps up files is encapsulated in the process_sgcn_source_item function from the pysgcn package. It picks up the messages, reads the specified file via URL into memory, and does some basic processing to harmonize across the slightly variable files as much as possible and infuse a little bit of additional metadata from the root collection item.\n",
    "\n",
    "The two pieces of additional information the function infuses come from files attached to the root collection. These include the following:\n",
    "\n",
    "* An indication of whether the name was included in the 2005 SWAP-based list coming from a master list stored from original processing. This helps us maintain consistency in total counts of species.\n",
    "* A number of names had to be tracked down with a bit of research to assign ITIS TSN identifiers. These serve as overrides to the name matching process.\n",
    "\n",
    "Each dataset can be processed at this stage and stand on its own somewhere. The point here is to get the original data file from ScienceBase, making sure we can read it into memory as a dataframe, infusing the extra information from the reference files stored at the collection, and then stashing the data somewhere online for further processing in later steps. I put all of that logic together into the cache_item_data function that calls the more fundamental processing function, process_sgcn_source_item. The caching function will check the cache when called to make sure the cache is intact and then delete the message if that's the case. Or it will go ahead and fire the processing function to retrieve and process the file and then write it to cache. For this exercise, I cache the data to a folder within the space designated by the DATA_CACHE environment variable as a feather binary file. These are lightweight, fast, and easy to work with across programs. For the online instantiation of this workflow, we will probably want to go ahead and write them to a relational database as we can later assemble them from there into final usable data.\n",
    "\n",
    "I run the process as a while loop on the messages in temporary storage, but this will run as messages that get flushed from the queue as lambdas operate on them.\n",
    "\n",
    "Note: I have experienced some variation in the speed of this step, which seem to track back to ScienceBase variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysgcn\n",
    "sgcn = pysgcn.sgcn.Sgcn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing source data requires the availability of some additional information stashed with the source collection in ScienceBase. The following function grabs up the attached files and caches them in the local Sqlite database for further use. The 'Historic 2005 SWAP National List' and 'SGCN ITIS Overrides' files are the ones required at this stage to infuse two bits of information into the records. The others are required at later stages in the process. Alternatively, these files can be read from ScienceBase every time they are needed, but that puts unnecessary strain on that part of the process. For our production solution, we may want to spin these up behind an API for access in the processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Historic 2005 SWAP National List',\n",
       " 'SGCN ITIS Overrides',\n",
       " 'Taxonomic Group Mappings',\n",
       " 'Hierarchy for FWS Listing Status',\n",
       " 'NatureServe National Conservation Status Descriptions',\n",
       " 'Fish and Wildlife Service Endangered Species Program Species Status Codes']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgcn.cache_sgcn_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7a0c674127556e803ccb4bcaf40483dd0631ee7e',\n",
       " 'date_inserted': '2019-12-17T14:38:57.525212',\n",
       " 'body': {'sciencebase_item_id': 'https://www.sciencebase.gov/catalog/item/5787cd0ae4b0d27deb3754f2',\n",
       "  'state': 'Louisiana',\n",
       "  'year': '2005',\n",
       "  'source_file_url': 'https://www.sciencebase.gov/catalog/file/get/5787cd0ae4b0d27deb3754f2?f=__disk__b4%2Fae%2Fbf%2Fb4aebf82009a2aaadaa4d7b84fdcade7589c722b',\n",
       "  'source_file_date': '2016-07-14T17:33:42.000Z'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processable_item = sgcn.get_message(\"mq_sgcn_items\")\n",
    "processable_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 1min 54s, total: 4min 10s\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while processable_item is not None:\n",
    "    sgcn.cache_item_data(processable_item[\"body\"])\n",
    "    sgcn.delete_message(\"mq_sgcn_items\", processable_item[\"id\"])\n",
    "    processable_item = sgcn.get_message(\"mq_sgcn_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
